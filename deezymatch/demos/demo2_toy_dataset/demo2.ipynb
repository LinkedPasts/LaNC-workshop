{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo 2\n",
    "\n",
    "In this demo, we start with a dataset, train a new DeezyMatch model and use it for the task of candidate ranking. The steps are as follows:\n",
    "\n",
    "1. Train a new DeezyMatch model using **a toy dataset with 1K rows**. We chose such a small dataset so that the training can be done within few seconds. If you want to try this demo on other **realistic** datasets, we have:\n",
    "\n",
    "```python\n",
    "dataset_path=\"../../dataset/BL_IAMS_geonames.tsv\"\n",
    "```\n",
    "\n",
    "on the repo.\n",
    "\n",
    "2. Fine-tune the model trained in step 1.\n",
    "3. Model inference.\n",
    "4. Generate query and candidate vector representations, assemble them so that they can be used for the next steps.\n",
    "5. Candidate ranking using a set of \"static\" queries.\n",
    "6. Candidate ranking on the fly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from DeezyMatch import train as dm_train\n",
    "\n",
    "# train a new model\n",
    "dm_train(input_file_path=\"./inputs/input_dfm_demo2.yaml\", \n",
    "         dataset_path=\"../../dataset/dummy_trainset.txt\",\n",
    "         model_name=\"demo2_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finetune a pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from DeezyMatch import finetune as dm_finetune\n",
    "\n",
    "# fine-tune a pretrained model stored at pretrained_model_path and pretrained_vocab_path \n",
    "dm_finetune(input_file_path=\"./inputs/input_dfm_demo2.yaml\", \n",
    "            dataset_path=\"../../dataset/dummy_trainset.txt\", \n",
    "            model_name=\"ft_demo2_model\",\n",
    "            pretrained_model_path=\"./models/demo2_model/demo2_model.model\", \n",
    "            pretrained_vocab_path=\"./models/demo2_model/demo2_model.vocab\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from DeezyMatch import inference as dm_inference\n",
    "\n",
    "# model inference using a model stored at pretrained_model_path and pretrained_vocab_path \n",
    "dm_inference(input_file_path=\"./inputs/input_dfm_demo2.yaml\",\n",
    "             dataset_path=\"../../dataset/dummy_trainset.txt\", \n",
    "             pretrained_model_path=\"./models/ft_demo2_model/ft_demo2_model.model\", \n",
    "             pretrained_vocab_path=\"./models/ft_demo2_model/ft_demo2_model.vocab\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate query vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DeezyMatch import inference as dm_inference\n",
    "\n",
    "# generate vectors for queries (specified in dataset_path) \n",
    "# using a model stored at pretrained_model_path and pretrained_vocab_path \n",
    "dm_inference(input_file_path=\"./inputs/input_dfm_demo2.yaml\",\n",
    "            dataset_path=\"../../query_scenarios/ukcounties_queries.txt\", \n",
    "            pretrained_model_path=\"./models/ft_demo2_model/ft_demo2_model.model\", \n",
    "            pretrained_vocab_path=\"./models/ft_demo2_model/ft_demo2_model.vocab\",\n",
    "            inference_mode=\"vect\",\n",
    "            scenario=\"queries/demo2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate candidate vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DeezyMatch import inference as dm_inference\n",
    "\n",
    "# generate vectors for candidates (specified in dataset_path) \n",
    "# using a model stored at pretrained_model_path and pretrained_vocab_path \n",
    "dm_inference(input_file_path=\"./inputs/input_dfm_demo2.yaml\",\n",
    "            dataset_path=\"../../candidate_scenarios/ukcounties_candidates.txt\", \n",
    "            pretrained_model_path=\"./models/ft_demo2_model/ft_demo2_model.model\", \n",
    "            pretrained_vocab_path=\"./models/ft_demo2_model/ft_demo2_model.vocab\",\n",
    "            inference_mode=\"vect\",\n",
    "            scenario=\"candidates/demo2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assembling queries vector representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from DeezyMatch import combine_vecs\n",
    "\n",
    "# combine vectors stored in queries/test and save them in combined/queries_test\n",
    "combine_vecs(rnn_passes=['fwd', 'bwd'], \n",
    "             input_scenario='queries/demo2', \n",
    "             output_scenario='combined/queries_demo2', \n",
    "             print_every=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assembling candidates vector representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from DeezyMatch import combine_vecs\n",
    "\n",
    "# combine vectors stored in candidates/test and save them in combined/candidates_test\n",
    "combine_vecs(rnn_passes=['fwd', 'bwd'], \n",
    "             input_scenario='candidates/demo2', \n",
    "             output_scenario='combined/candidates_demo2', \n",
    "             print_every=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Candidate Ranker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from DeezyMatch import candidate_ranker\n",
    "\n",
    "# Select candidates based on L2-norm distance (aka faiss distance):\n",
    "# find candidates from candidate_scenario \n",
    "# for queries specified in query_scenario\n",
    "candidates_pd = \\\n",
    "    candidate_ranker(query_scenario=\"./combined/queries_demo2\",\n",
    "                     candidate_scenario=\"./combined/candidates_demo2\", \n",
    "                     ranking_metric=\"faiss\", \n",
    "                     selection_threshold=100., \n",
    "                     num_candidates=5, \n",
    "                     search_size=5, \n",
    "                     output_path=\"ranker_results/candidates_deezymatch_demo2\", \n",
    "                     pretrained_model_path=\"./models/ft_demo2_model/ft_demo2_model.model\", \n",
    "                     pretrained_vocab_path=\"./models/ft_demo2_model/ft_demo2_model.vocab\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "candidates_pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Candidate ranking on-the-fly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from DeezyMatch import candidate_ranker\n",
    "\n",
    "# Ranking on-the-fly\n",
    "# find candidates from candidate_scenario \n",
    "# for queries specified by the `query` argument\n",
    "candidates_pd = \\\n",
    "    candidate_ranker(query=[\"lincoln\", \"warwick\"],\n",
    "                     candidate_scenario=\"./combined/candidates_demo2\", \n",
    "                     ranking_metric=\"faiss\", \n",
    "                     selection_threshold=100., \n",
    "                     num_candidates=5, \n",
    "                     search_size=5, \n",
    "                     output_path=\"ranker_results/candidates_deezymatch_demo2\", \n",
    "                     pretrained_model_path=\"./models/ft_demo2_model/ft_demo2_model.model\", \n",
    "                     pretrained_vocab_path=\"./models/ft_demo2_model/ft_demo2_model.vocab\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates_pd"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
